{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fe7e6c",
   "metadata": {},
   "source": [
    "数据集的目录结构如下：\n",
    "\n",
    "```Text\n",
    "data/\n",
    "└── images\n",
    "    ├── train\n",
    "    │   ├── 1\n",
    "    │   └── ……\n",
    "    └── val\n",
    "        ├── 1\n",
    "        └── ……\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8f61d",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "\n",
    "狼狗数据集提取自ImageNet分类数据集，使用`mindspore.dataset.ImageFolderDataset`接口来加载数据集，并进行相关图像增强操作。  \n",
    "\n",
    "首先执行过程定义一些输入："
   ]
  },
  {
   "cell_type": "code",
   "id": "069fbe0c",
   "metadata": {},
   "source": [
    "batch_size = 18                             # 批量大小\n",
    "image_size = 224                            # 训练图像空间大小\n",
    "num_epochs = 10                             # 训练周期数\n",
    "lr = 0.001                                  # 学习率\n",
    "momentum = 0.9                              # momentum\n",
    "workers = 7                                 # 并行线程个数"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3829ef7",
   "metadata": {},
   "source": [
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "\n",
    "# 数据集目录路径\n",
    "data_path_train = \"./data/images/train/\"\n",
    "data_path_val = \"./data/images/val/\"\n",
    "\n",
    "# 创建训练数据集\n",
    "\n",
    "def create_dataset_canidae(dataset_path, usage):\n",
    "    \"\"\"数据加载\"\"\"\n",
    "    data_set = ds.ImageFolderDataset(dataset_path,\n",
    "                                     num_parallel_workers=workers,\n",
    "                                     shuffle=True,)\n",
    "\n",
    "    # 数据增强操作\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "    scale = 32\n",
    "\n",
    "    if usage == \"train\":\n",
    "        # Define map operations for training dataset\n",
    "        trans = [\n",
    "            vision.RandomCropDecodeResize(size=image_size, scale=(0.08, 1.0), ratio=(0.75, 1.333)),\n",
    "            vision.RandomHorizontalFlip(prob=0.5),\n",
    "            vision.Normalize(mean=mean, std=std),\n",
    "            vision.HWC2CHW()\n",
    "        ]\n",
    "    else:\n",
    "        # Define map operations for inference dataset\n",
    "        trans = [\n",
    "            vision.Decode(),\n",
    "            vision.Resize(image_size + scale),\n",
    "            vision.CenterCrop(image_size),\n",
    "            vision.Normalize(mean=mean, std=std),\n",
    "            vision.HWC2CHW()\n",
    "        ]\n",
    "\n",
    "\n",
    "    # 数据映射操作\n",
    "    data_set = data_set.map(\n",
    "        operations=trans,\n",
    "        input_columns='image',\n",
    "        num_parallel_workers=workers)\n",
    "\n",
    "\n",
    "    # 批量操作\n",
    "    data_set = data_set.batch(batch_size)\n",
    "\n",
    "    return data_set\n",
    "\n",
    "\n",
    "dataset_train = create_dataset_canidae(data_path_train, \"train\")\n",
    "step_size_train = dataset_train.get_dataset_size()\n",
    "\n",
    "dataset_val = create_dataset_canidae(data_path_val, \"val\")\n",
    "step_size_val = dataset_val.get_dataset_size()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4cc3ba3",
   "metadata": {},
   "source": [
    "### 数据集可视化\n",
    "\n",
    "从`mindspore.dataset.ImageFolderDataset`接口中加载的训练数据集返回值为字典，用户可通过 `create_dict_iterator` 接口创建数据迭代器，使用 `next` 迭代访问数据集。本章中 `batch_size` 设为18，所以使用 `next` 一次可获取18个图像及标签数据。"
   ]
  },
  {
   "cell_type": "code",
   "id": "25971977",
   "metadata": {},
   "source": [
    "data = next(dataset_train.create_dict_iterator())\n",
    "images = data[\"image\"]\n",
    "labels = data[\"label\"]\n",
    "\n",
    "print(\"Tensor of image\", images.shape)\n",
    "print(\"Labels:\", labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7024d4b0",
   "metadata": {},
   "source": [
    "对获取到的图像及标签数据进行可视化，标题为图像对应的label名称。"
   ]
  },
  {
   "cell_type": "code",
   "id": "41868a69",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# class_name对应label，按文件夹字符串从小到大的顺序标记label\n",
    "class_name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"8\", 6: \"11\", 7: \"12\",\n",
    "            8: \"13\",9: \"14\", 10: \"15\",11: \"16\", 12: \"17\",13: \"18\",14: \"19\",15: \"21\"}\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(4):\n",
    "    # 获取图像及其对应的label\n",
    "    data_image = images[i].asnumpy()\n",
    "    data_label = labels[i]\n",
    "    # 处理图像供展示使用\n",
    "    data_image = np.transpose(data_image, (1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    data_image = std * data_image + mean\n",
    "    data_image = np.clip(data_image, 0, 1)\n",
    "    # 显示图像\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(data_image)\n",
    "    plt.title(class_name[int(labels[i].asnumpy())])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "083f183d-0cc8-432a-8c5c-5f9f4164b1be",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "使用ResNet50模型进行训练。通过将`pretrained`参数设置为True来下载[ResNet50的预训练模型](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/models/application/resnet50_224_new.ckpt)并将权重参数加载到网络中。\n",
    "\n",
    "### 构建Resnet50网络"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fe49556",
   "metadata": {},
   "source": [
    "from typing import Type, Union, List, Optional\n",
    "from mindspore import nn, train\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore import context\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "\n",
    "weight_init = Normal(mean=0, sigma=0.02)\n",
    "gamma_init = Normal(mean=1, sigma=0.02)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2393283e",
   "metadata": {},
   "source": [
    "class ResidualBlockBase(nn.Cell):\n",
    "    expansion: int = 1  # 最后一个卷积核数量与第一个卷积核数量相等\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlockBase, self).__init__()\n",
    "        if not norm:\n",
    "            self.norm = nn.BatchNorm2d(out_channel)\n",
    "        else:\n",
    "            self.norm = norm\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=3, stride=stride,\n",
    "                               weight_init=weight_init)\n",
    "        self.conv2 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=3, weight_init=weight_init)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualBlockBase construct.\"\"\"\n",
    "        identity = x  # shortcuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：3*3卷积层\n",
    "        out = self.norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "        out = self.norm(out)\n",
    "\n",
    "        if self.down_sample is not None:\n",
    "            identity = self.down_sample(x)\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93a7f425",
   "metadata": {},
   "source": [
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4  # 最后一个卷积核的数量是第一个卷积核数量的4倍\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=1, weight_init=weight_init)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel,\n",
    "                               kernel_size=3, stride=stride,\n",
    "                               weight_init=weight_init)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(out_channel, out_channel * self.expansion,\n",
    "                               kernel_size=1, weight_init=weight_init)\n",
    "        self.norm3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "\n",
    "        identity = x  # shortscuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：1*1卷积层\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)  # 主分支第三层：1*1卷积层\n",
    "        out = self.norm3(out)\n",
    "\n",
    "        if self.down_sample is not None:\n",
    "            identity = self.down_sample(x)\n",
    "\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b374ff5",
   "metadata": {},
   "source": [
    "def make_layer(last_out_channel, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "               channel: int, block_nums: int, stride: int = 1):\n",
    "    down_sample = None  # shortcuts分支\n",
    "\n",
    "\n",
    "    if stride != 1 or last_out_channel != channel * block.expansion:\n",
    "\n",
    "        down_sample = nn.SequentialCell([\n",
    "            nn.Conv2d(last_out_channel, channel * block.expansion,\n",
    "                      kernel_size=1, stride=stride, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(channel * block.expansion, gamma_init=gamma_init)\n",
    "        ])\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(last_out_channel, channel, stride=stride, down_sample=down_sample))\n",
    "\n",
    "    in_channel = channel * block.expansion\n",
    "    # 堆叠残差网络\n",
    "    for _ in range(1, block_nums):\n",
    "\n",
    "        layers.append(block(in_channel, channel))\n",
    "\n",
    "    return nn.SequentialCell(layers)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01d14ca1",
   "metadata": {},
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    def __init__(self, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "                 layer_nums: List[int], num_classes: int, input_channel: int) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # 第一个卷积层，输入channel为3（彩色图像），输出channel为64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, weight_init=weight_init)\n",
    "        self.norm = nn.BatchNorm2d(64)\n",
    "        # 最大池化层，缩小图片的尺寸\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "        # 各个残差网络结构块定义，\n",
    "        self.layer1 = make_layer(64, block, 64, layer_nums[0])\n",
    "        self.layer2 = make_layer(64 * block.expansion, block, 128, layer_nums[1], stride=2)\n",
    "        self.layer3 = make_layer(128 * block.expansion, block, 256, layer_nums[2], stride=2)\n",
    "        self.layer4 = make_layer(256 * block.expansion, block, 512, layer_nums[3], stride=2)\n",
    "        # 平均池化层\n",
    "        self.avg_pool = nn.AvgPool2d()\n",
    "        # flattern层\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 全连接层\n",
    "        self.fc = nn.Dense(in_channels=input_channel, out_channels=num_classes)\n",
    "\n",
    "    def construct(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(model_url: str, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "            layers: List[int], num_classes: int, pretrained: bool, pretrianed_ckpt: str,\n",
    "            input_channel: int):\n",
    "    model = ResNet(block, layers, num_classes, input_channel)\n",
    "\n",
    "    if pretrained:\n",
    "        # 加载预训练模型\n",
    "        download(url=model_url, path=pretrianed_ckpt, replace=True)\n",
    "        param_dict = load_checkpoint(pretrianed_ckpt)\n",
    "        load_param_into_net(model, param_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(num_classes: int = 1000, pretrained: bool = False):\n",
    "    \"ResNet50模型\"\n",
    "    resnet50_url = \"https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/models/application/resnet50_224_new.ckpt\"\n",
    "    resnet50_ckpt = \"./LoadPretrainedModel/resnet50_224_new.ckpt\"\n",
    "    return _resnet(resnet50_url, ResidualBlock, [3, 4, 6, 3], num_classes,\n",
    "                   pretrained, resnet50_ckpt, 2048)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db130d3d",
   "metadata": {},
   "source": [
    "### 模型微调\n",
    "\n",
    "由于ResNet50中的预训练模型是针对ImageNet数据集中的1000个类别进行分类的，在本章只对狼和狗两个类别进行分类，所以需要重置预训练模型中的分类器，然后重新微调网络。"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ae3bcfd",
   "metadata": {},
   "source": [
    "from download import download\n",
    "import mindspore as ms\n",
    "\n",
    "network = resnet50(pretrained=False)\n",
    "\n",
    "# 全连接层输入层的大小\n",
    "in_channels = network.fc.in_channels\n",
    "# 输出通道数大小为树种分类数16\n",
    "head = nn.Dense(in_channels, 16)\n",
    "# 重置全连接层\n",
    "network.fc = head\n",
    "\n",
    "# 平均池化层kernel size为7\n",
    "avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "# 重置平均池化层\n",
    "network.avg_pool = avg_pool"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8fc8ca21",
   "metadata": {},
   "source": [
    "import mindspore as ms\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "opt = nn.Momentum(params=network.trainable_params(), learning_rate=lr, momentum=momentum)\n",
    "loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 实例化模型\n",
    "model = train.Model(network, loss_fn, opt, metrics={\"Accuracy\": train.Accuracy()})\n",
    "\n",
    "def forward_fn(inputs, targets):\n",
    "\n",
    "    logits = network(inputs)\n",
    "    loss = loss_fn(logits, targets)\n",
    "\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, opt.parameters)\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "\n",
    "    loss, grads = grad_fn(inputs, targets)\n",
    "    opt(grads)\n",
    "\n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35ecf788",
   "metadata": {},
   "source": [
    "#### 训练和评估\n",
    "\n",
    "训练并评估网络，且在训练完成后，保存评估精度最高的ckpt文件(resnet50-best.ckpt)到当前路径的/BestCheckpoint下，保存路径和ckpt文件名可自行调整。"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7d2c421",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 创建迭代器\n",
    "data_loader_train = dataset_train.create_tuple_iterator(num_epochs=num_epochs)\n",
    "\n",
    "# 最佳模型保存路径\n",
    "best_ckpt_dir = \"./BestCheckpoint\"\n",
    "best_ckpt_path = \"./BestCheckpoint/resnet50-best.ckpt\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "772453d1-51c1-40c8-9648-2898f15bfda0",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb04d051",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# 开始循环训练\n",
    "print(\"Start Training Loop ...\")\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    network.set_train()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # 为每轮训练读入数据\n",
    "    for i, (images, labels) in enumerate(data_loader_train):\n",
    "        labels = labels.astype(ms.int32)\n",
    "        loss = train_step(images, labels)\n",
    "        losses.append(loss)\n",
    "\n",
    "    # 每个epoch结束后，验证准确率\n",
    "\n",
    "    acc = model.eval(dataset_val)['Accuracy']\n",
    "\n",
    "    epoch_end = time.time()\n",
    "    epoch_seconds = (epoch_end - epoch_start) * 1000\n",
    "    step_seconds = epoch_seconds/step_size_train\n",
    "\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Epoch: [%3d/%3d], Average Train Loss: [%5.3f], Accuracy: [%5.3f]\" % (\n",
    "        epoch+1, num_epochs, sum(losses)/len(losses), acc\n",
    "    ))\n",
    "    print(\"epoch time: %5.3f ms, per step time: %5.3f ms\" % (\n",
    "        epoch_seconds, step_seconds\n",
    "    ))\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        if not os.path.exists(best_ckpt_dir):\n",
    "            os.mkdir(best_ckpt_dir)\n",
    "        ms.save_checkpoint(network, best_ckpt_path)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"End of validation the best Accuracy is: {best_acc: 5.3f}, \"\n",
    "      f\"save the best ckpt file in {best_ckpt_path}\", flush=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bca1878-f1ea-415b-9cbe-98b432921518",
   "metadata": {},
   "source": [
    "#### 可视化模型预测\n",
    "\n",
    "定义 `visualize_mode` 函数，可视化模型预测。"
   ]
  },
  {
   "cell_type": "code",
   "id": "dea3aa52",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mindspore as ms\n",
    "\n",
    "def visualize_model(best_ckpt_path, val_ds):\n",
    "    net = resnet50()\n",
    "    # 全连接层输入层的大小\n",
    "    in_channels = net.fc.in_channels\n",
    "    # 输出通道数大小为树种分类数16\n",
    "    head = nn.Dense(in_channels, 16)\n",
    "    # 重置全连接层\n",
    "    net.fc = head\n",
    "    # 平均池化层kernel size为7\n",
    "    avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "    # 重置平均池化层\n",
    "    net.avg_pool = avg_pool\n",
    "    # 加载模型参数\n",
    "    param_dict = ms.load_checkpoint(best_ckpt_path)\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "    model = train.Model(net)\n",
    "    # 加载验证集的数据进行验证\n",
    "    data = next(val_ds.create_dict_iterator())\n",
    "    images = data[\"image\"].asnumpy()\n",
    "    labels = data[\"label\"].asnumpy()\n",
    "    class_name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"8\", 6: \"11\", 7: \"12\",\n",
    "            8: \"13\",9: \"14\", 10: \"15\",11: \"16\", 12: \"17\",13: \"18\",14: \"19\",15: \"21\"}\n",
    "    # 预测图像类别\n",
    "    output = model.predict(ms.Tensor(data['image']))\n",
    "    pred = np.argmax(output.asnumpy(), axis=1)\n",
    "\n",
    "    # 显示图像及图像的预测值\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        # 若预测正确，显示为蓝色；若预测错误，显示为红色\n",
    "        color = 'blue' if pred[i] == labels[i] else 'red'\n",
    "        plt.title('predict:{}'.format(class_name[pred[i]]), color=color)\n",
    "        picture_show = np.transpose(images[i], (1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        picture_show = std * picture_show + mean\n",
    "        picture_show = np.clip(picture_show, 0, 1)\n",
    "        plt.imshow(picture_show)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8389b9be",
   "metadata": {},
   "source": [
    "使用模型微调得到的best.ckpt文件对验证集的狼和狗图像数据进行预测。若预测字体为蓝色表示预测正确，若预测字体为红色表示预测错误。"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f2511e7",
   "metadata": {},
   "source": [
    "visualize_model(best_ckpt_path, dataset_val)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore[1.10.1]",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b352d89025746abfd3d4fa7053c22c36b9d81e9898372aef9407193f0acc45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
